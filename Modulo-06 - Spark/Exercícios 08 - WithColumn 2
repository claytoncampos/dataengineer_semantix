1. Criar um dataframe para ler o arquivo no HDFS /user/<nome/data/juros_selic/juros_selic
f_juros_selic = spark.read.csv("/user/clayton/data/juros_selic/juros_selic", header="true", sep=";").show()

2. Agrupar todas as datas pelo ano em ordem decrescente e salvar a quantidade de meses ocorridos, o valor médio, mínimo e máximo do campo valor com a seguinte estrutura:

Anual 	 Meses 	Valor médio  	 Valor Mínimo		Valor Máximo
2019	 2		00.00		00.00			00.00	
2018	 2		00.00		00.00			00.00	
2017	 2		00.00		00.00			00.00	
...	 ...		00.00		00.00			00.00	
1986	2		00.00		00.00			00.00	


juros_relatorio = df_juros_valor.groupBy("ano").agg(count("ano").alias("Meses"),format_number(avg("valor"),2).alias("Valor médio"), min("valor").alias("Valor Minimo"), max("valor").alias("Valor Máximo")).sort(desc("ano")).show()

3. Salvar no hdfs:///user/<nome>/relatorioAnual com compressão zlib e formato orc
juros_relatorio.write.orc("/user/clayton/relatorioAnual",compression="zlib")
