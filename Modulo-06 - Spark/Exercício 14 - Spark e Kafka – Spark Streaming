Kafka

1. Preparação do ambiente no Kafka

a) Criar o tópico “topic-kvspark” com 2 partições e o fator de replicação = 1
kafka-topics.sh --bootstrap-server kafka:9092 --create --topic topic-kvspark --partitions 2 --replication-factor 1


b) Inserir as seguintes mensagens no tópico (Chave, Valor):
kafka-console-producer.sh --broker-list kafka:9092 --topic topic-kvspark --property parse.key=true --property key.separator=,

o 1, Msg1

o 2, Msg2

o 3, Msg3



c) Criar um consumidor no Kafka para ler o “topic-kvspark”
kafka-console-consumer.sh --bootstrap-server kafka:9092 --topic topic-kvspark
Spark

1. Criar um consumidor em Scala usando Spark Streaming para ler o “topic-kvspark” no cluster Kafka ”kafka:9092”

spark-shell --packages org.apache.spark:spark-streaming-kafka-0-10_2.11:2.4.1
import org.apache.kafka.clients.consumer.ConsumerRecord
import org.apache.kafka.common.serialization.StringDeserializer
import org.apache.spark.streaming.kafka010._
import org.apache.spark.streaming.kafka010.LocationStrategies.PreferConsistent
import org.apache.spark.streaming.kafka010.ConsumerStrategies.Subscribe
import org.apache.spark.streaming.{StreamingContext, Seconds}

val kafkaParams = Map[String, Object](
	"bootstrap.servers" -> "kafka:9092",
	"key.deserializer" -> classOf[StringDeserializer],
	"value.deserializer" -> classOf[StringDeserializer],
	"group.id" -> "aplicacao2",
	"auto.offset.reset" -> "earliest",
	"enable.auto.commit" -> (false: java.lang.Boolean)
)
#criando o contexto sparkStreaming
val ssc = new StreamingContext(sc, Seconds(5))

#lendo o topico
val topics = Array("topic-kvspark")
val streams = KafkaUtils.createDirectStream[String, String](
	ssc,
	PreferConsistent,
	Subscribe[String, String](topics, kafkaParams)
)


2. Visualizar o tópico com as seguintes informações

    Nome do tópico
    Partição
    Chave
    Valor

val info_stream = streams.map(record => (record.topic, 
	record.partition,
	record.key,
	record.value)
)

info_stream.print()

3. Salvar o tópico no diretório hdfs://namenode:8020/user/<nome>/kafka/dstreamkv
info_stream .saveAsTextFiles("hdfs://namenode:8020/user/clayton/kafka/dstreamkv ")

ssc.start()

4. Clicar no botão de Enviar Tarefa, e enviar o texto: ok
